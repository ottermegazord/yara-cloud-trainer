{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Add TF GPU for Jetson TX2\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "# tf.__version__, tf.test.is_gpu_available(), tf.test.is_built_with_cuda(), tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "# print(os.listdir(os.path.join(data_dir, 'cirrocumulus', '*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/cirrocumulus/*.jpg\n"
     ]
    }
   ],
   "source": [
    "image_dir = os.path.join(data_dir, 'cirrocumulus', '*.jpg')\n",
    "print(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _img_string_to_tensor(image_string, image_size=(40, 40)):\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    # Convert from full range of uint8 to range [0,1] of float32.\n",
    "    image_decoded_as_float = tf.image.convert_image_dtype(image_decoded, dtype=tf.float32)\n",
    "    # Resize to expected\n",
    "    image_resized = tf.image.resize_images(image_decoded_as_float, size=image_size)\n",
    "    \n",
    "    return image_resized\n",
    "\n",
    "def make_input_fn(file_pattern, image_size=(40, 40), shuffle=False, batch_size=64, num_epochs=None, buffer_size=4096):\n",
    "    \n",
    "    def _path_to_img(path):\n",
    "        # Get the parent folder of this file to get it's class name\n",
    "        label = tf.string_split([path], delimiter='/').values[-2]\n",
    "        print(path)\n",
    "        # Read in the image from disk\n",
    "        image_string = tf.read_file(path)\n",
    "        image_resized = _img_string_to_tensor(image_string, image_size)\n",
    "        \n",
    "        return image_resized, label\n",
    "    \n",
    "    def _input_fn():\n",
    "        \n",
    "        dataset = tf.data.Dataset.list_files(file_pattern)\n",
    "\n",
    "        if shuffle:\n",
    "            dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(buffer_size, num_epochs))\n",
    "        else:\n",
    "            dataset = dataset.repeat(num_epochs)\n",
    "\n",
    "        dataset = dataset.map(_path_to_img, num_parallel_calls=os.cpu_count())\n",
    "        dataset = dataset.batch(batch_size).prefetch(buffer_size)\n",
    "\n",
    "        return dataset\n",
    "    \n",
    "    dataset = _input_fn()\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 10000\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"arg0:0\", shape=(), dtype=string)\n",
      "<PrefetchDataset shapes: ((?, 64, 64, 3), (?,)), types: (tf.float32, tf.string)>\n"
     ]
    }
   ],
   "source": [
    "dataset = make_input_fn(image_dir, image_size=(64,64), batch_size=batch_size, shuffle=True)\n",
    "print(dataset)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define DCGAN network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim_image = 2352 # 28 * 28 * 3\n",
    "# gen_hidden_dim = 256\n",
    "# dis_hidden_dim = 256\n",
    "n_noise = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep_prob= tf.placeholder(dtype=tf.float32, name='keep_prob')\n",
    "# is_training= tf.placeholder(dtype=tf.bool, name='is_training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define DCGAN functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen(x, reuse=False):\n",
    "    with tf.variable_scope('Generator', reuse=reuse):\n",
    "#         # TensorFlow Layers automatically create variables and calculate their\n",
    "#         # shape, based on the input.\n",
    "#         x = tf.layers.dense(x, units=6 * 6 * 128)\n",
    "#         x = tf.nn.tanh(x)\n",
    "#         # Reshape to a 4-D array of images: (batch, height, width, channels)\n",
    "#         # New shape: (batch, 6, 6, 128)\n",
    "#         x = tf.reshape(x, shape=[-1, 6, 6, 128])\n",
    "#         # Deconvolution, image shape: (batch, 14, 14, 64)\n",
    "#         x = tf.layers.conv2d_transpose(x, 64, 4, strides=2)\n",
    "#         # Deconvolution, image shape: (batch, 28, 28, 1)\n",
    "#         x = tf.layers.conv2d_transpose(x, 1, 2, strides=2)\n",
    "#         # Apply sigmoid to clip values between 0 and 1\n",
    "#         x = tf.nn.sigmoid(x)\n",
    "\n",
    "        # TensorFlow Layers automatically create variables and calculate their\n",
    "        # shape, based on the input.\n",
    "        \n",
    "        '''Layer 1'''\n",
    "        x = tf.layers.dense(x, units=4*4*1024)\n",
    "        x = tf.reshape(x, shape=[-1, 4, 4, 1024])\n",
    "        x = tf.layers.batch_normalization(x, training=True)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.2)\n",
    "        print(x.shape)\n",
    "        \n",
    "        '''Layer 2'''\n",
    "        x = tf.layers.conv2d_transpose(x, 512, 3, strides=2,\n",
    "                                      padding='SAME')\n",
    "        x = tf.layers.batch_normalization(x, training=True)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.2)\n",
    "        print(x.shape)\n",
    "        '''Layer 3'''\n",
    "        x = tf.layers.conv2d_transpose(x, 256, 3, strides=2,\n",
    "                                      padding='SAME')\n",
    "        x = tf.layers.batch_normalization(x, training=True)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.2)\n",
    "        print(x.shape)\n",
    "        '''Layer 4'''\n",
    "        x = tf.layers.conv2d_transpose(x, 128, 3, strides=2,\n",
    "                                      padding='SAME')\n",
    "        x = tf.layers.batch_normalization(x, training=True)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.2)\n",
    "        print(x.shape)\n",
    "\n",
    "        '''Layer 6'''\n",
    "        x = tf.layers.conv2d_transpose(x, 3, 2, strides=2,\n",
    "                                      padding='SAME')\n",
    "        print(x.shape)\n",
    "        x = tf.nn.tanh(x)\n",
    "        return x\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dis(x, reuse=False):\n",
    "    \n",
    "\n",
    "    with tf.variable_scope('Discriminator', reuse=reuse):\n",
    "        \n",
    "#         '''Layer 1'''\n",
    "#         x = tf.layers.dense(x, units=16*16*128)\n",
    "#         x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "#         x = tf.layers.batch_normalization(x, training=True, momentum=0.9)\n",
    "#         x = tf.reshape(x, shape=[-1, 16, 16, 128])\n",
    "#         print(x.shape)\n",
    "        \n",
    "#         '''Layer 2'''\n",
    "#         x = tf.layers.conv2d(x, 128, kernel_size=(5,5), strides=1, padding='SAME')\n",
    "#         x = tf.layers.batch_normalization(x, training=True, momentum=0.9)\n",
    "#         x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "#         print(x.shape)\n",
    "        \n",
    "#         '''Layer 3'''\n",
    "#         x = tf.layers.conv2d_transpose(x, 128, kernel_size(2,2), strides=1, padding='SAME')\n",
    "#         x = tf.layers.batch_normalization(x, training=True, momentum=0.9)\n",
    "#         x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "#         print(x.shape)\n",
    "        \n",
    "#         '''Layer 4'''\n",
    "#         x = tf.layers.conv2d_transpose(x, 128, kernel_size(2,2), strides=1, padding='SAME')\n",
    "#         x = tf.layers.batch_normalization(x, training=True, momentum=0.9)\n",
    "#         x = tf.nn.leaky_relu(x, alpha=0.1)\n",
    "#         print(x.shape)\n",
    "        \n",
    "#         '''Layer 5'''\n",
    "#         x = tf.layers.conv2d(x, 3, kernel_size(5,5), strides=1, padding='SAME')\n",
    "#         print(x.shape)\n",
    "#         x = tf.nn.tanh(x)\n",
    "        \n",
    "\n",
    "        \"\"\"Layer 1\"\"\"\n",
    "        x = tf.layers.conv2d(x, kernel_size=4, filters=64, strides=2, \n",
    "                             padding='same')\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.2)      \n",
    "        \"\"\"Layer 2\"\"\"\n",
    "        x = tf.layers.conv2d(x, kernel_size=4, filters=128, strides=2, \n",
    "                             padding='same')\n",
    "        x = tf.layers.batch_normalization(x, training=True)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.2)\n",
    "\n",
    "        \"\"\"Layer 3\"\"\"\n",
    "        x = tf.layers.conv2d(x, kernel_size=4, filters=256, strides=2, \n",
    "                             padding='same')\n",
    "        x = tf.layers.batch_normalization(x, training=True)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.2)\n",
    "\n",
    "        \"\"\"Layer 4\"\"\"\n",
    "        x = tf.layers.conv2d(x, kernel_size=4, filters=512, strides=2, \n",
    "                             padding='same')\n",
    "        x = tf.layers.batch_normalization(x, training=True)\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.2)\n",
    "        \n",
    "        \n",
    "        \"\"\"Layer 5\"\"\"\n",
    "        x = tf.contrib.layers.flatten(x)\n",
    "        x = tf.layers.dense(x, 1024)\n",
    "        x = tf.nn.tanh(x)\n",
    "        x = tf.layers.dense(x, 2)\n",
    "        \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create placeholders for inputs to GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_noise = tf.placeholder(tf.float32, shape=[None, n_noise])\n",
    "real_input_image = tf.placeholder(tf.float32, shape=[None, 64, 64, 3])\n",
    "input_noise = tf.placeholder(tf.float32, shape=[None, n_noise])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create generator network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4, 4, 1024)\n",
      "(?, 8, 8, 512)\n",
      "(?, 16, 16, 256)\n",
      "(?, 32, 32, 128)\n",
      "(?, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "generator = gen(input_noise, reuse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create discriminator networks for fake and real images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_dis = dis(real_input_image) # Discriminator for real images\n",
    "fake_dis = dis(generator, reuse=True) # Discriminator for generated samples\n",
    "\n",
    "# Concatenate both together\n",
    "dis_concat = tf.concat([real_dis, fake_dis], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack generator on discriminator\n",
    "stacked_gan = dis(generator, reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_target = tf.placeholder(tf.int32, shape=[None])\n",
    "gen_target = tf.placeholder(tf.int32, shape=[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and build loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=dis_concat, labels=dis_target))\n",
    "gen_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=stacked_gan, labels=gen_target))\n",
    "\n",
    "# dis_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=dis_concat, labels=dis_target))\n",
    "# gen_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=stacked_gan, labels=gen_target))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define separate training variables for each optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator network variables\n",
    "gen_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Generator')\n",
    "dis_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='Discriminator')\n",
    "\n",
    "# Define optimizers\n",
    "optimizer_gen = tf.train.AdamOptimizer(learning_rate=0.0002, beta1=0.5)\n",
    "optimizer_dis = tf.train.AdamOptimizer(learning_rate=0.0002, beta1=0.5)\n",
    "\n",
    "# Create training variables\n",
    "train_gen = optimizer_gen.minimize(gen_loss, var_list=gen_vars)\n",
    "train_dis = optimizer_gen.minimize(dis_loss, var_list=dis_vars)\n",
    "\n",
    "# initialize variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Generator Loss: 0.746361, Discriminator Loss: 0.851251\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    sess.run(iterator.initializer)\n",
    "    for i in range(1, num_steps+1):\n",
    "        # Prepare Input Data\n",
    "        # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "        batch_x, _ = sess.run(next_element)\n",
    "        batch_x = np.reshape(batch_x, newshape=[-1, 64, 64, 3])\n",
    "        # Generate noise to feed to the generator\n",
    "        z = np.random.normal(-1., 1., size=[batch_size, n_noise])\n",
    "\n",
    "        # Prepare Targets (Real image: 1, Fake image: 0)\n",
    "        # The first half of data fed to the generator are real images,\n",
    "        # the other half are fake images (coming from the generator).\n",
    "        batch_disc_y = np.concatenate(\n",
    "            [np.ones([batch_size]), np.zeros([batch_size])], axis=0)\n",
    "        # Generator tries to fool the discriminator, thus targets are 1.\n",
    "        batch_gen_y = np.ones([batch_size])\n",
    "\n",
    "        # Training\n",
    "        feed_dict = {real_input_image: batch_x, input_noise: z,\n",
    "                     dis_target: batch_disc_y, gen_target: batch_gen_y}\n",
    "        \n",
    "#         print(\"step: %i\" %i)\n",
    "        \n",
    "        _, _, gl, dl = sess.run([train_gen, train_dis, gen_loss, dis_loss],\n",
    "                                feed_dict=feed_dict)\n",
    "#         _, _, gl, dl = sess.run([train_gen, train_dis, gen_loss, dis_loss],\n",
    "#                                 feed_dict=feed_dict)\n",
    "        if i % 100 == 0 or i == 1:\n",
    "            print('Step %i: Generator Loss: %f, Discriminator Loss: %f' % (i, gl, dl))\n",
    "            \n",
    "        if i % 1000 == 0:\n",
    "            f, a = plt.subplots(4, 10, figsize=(10, 10))\n",
    "            for b in range(10):\n",
    "                # Noise input.\n",
    "                z_test = np.random.uniform(-1., 1., size=[4, n_noise])\n",
    "                g_test = sess.run(generator, feed_dict={input_noise: z_test})\n",
    "                for j in range(4):\n",
    "                    # Generate image from noise. Extend to 3 channels for matplot figure.\n",
    "                    img = np.reshape(np.repeat(g_test[j][:, :, np.newaxis], 1, axis=2),\n",
    "                                     newshape=(64, 64, 3))\n",
    "                    a[j][b].imshow((img*255).astype(np.uint8))\n",
    "            f.show()\n",
    "            plt.show()\n",
    "\n",
    "    # Generate images from noise, using the generator network.\n",
    "    f, a = plt.subplots(4, 10, figsize=(10, 4))\n",
    "    for i in range(10):\n",
    "        # Noise input.\n",
    "        z = np.random.uniform(-1., 1., size=[4, n_noise])\n",
    "        g = sess.run(generator, feed_dict={input_noise: z})\n",
    "        for j in range(4):\n",
    "            # Generate image from noise. Extend to 3 channels for matplot figure.\n",
    "            img = np.reshape(np.repeat(g[j][:, :, np.newaxis], 1, axis=2),\n",
    "                             newshape=(64, 64, 3))\n",
    "            a[j][i].imshow(img)\n",
    "\n",
    "    f.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
